<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://zy080080.github.io/</id>
    <title>听故事的人</title>
    <updated>2021-01-17T14:42:18.491Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://zy080080.github.io/"/>
    <link rel="self" href="https://zy080080.github.io/atom.xml"/>
    <subtitle>天青色等烟雨，而我在等你</subtitle>
    <logo>https://zy080080.github.io/images/avatar.png</logo>
    <icon>https://zy080080.github.io/favicon.ico</icon>
    <rights>All rights reserved 2021, 听故事的人</rights>
    <entry>
        <title type="html"><![CDATA[OS：主記憶管理ー主記憶割り当て]]></title>
        <id>https://zy080080.github.io/post/ES4qIO3DM/</id>
        <link href="https://zy080080.github.io/post/ES4qIO3DM/">
        </link>
        <updated>2021-01-17T15:41:41.000Z</updated>
        <summary type="html"><![CDATA[<p>教科書第8章　まとめ</p>
]]></summary>
        <content type="html"><![CDATA[<p>教科書第8章　まとめ</p>
<!-- more -->
<p>領域要求のタイミング：</p>
<ul>
<li>静的（static）要求
<ul>
<li>プログラム実行開始時に必要領域を要求</li>
</ul>
</li>
<li>動的（dynamic）要求
<ul>
<li>プログラム実行開始時に最低限の領域を要求</li>
<li>実行につれてさらに必要となった場合はその都度要求</li>
</ul>
</li>
</ul>
<p><strong>固定区画方式</strong>：</p>
<ul>
<li>プロセスに割り当てる領域の大きさをあらかじめ決めておく</li>
<li>プロセスから要求があった際，その決められた大きさの領域を割り当てる</li>
<li>特徴：
<ul>
<li>新しいプロセスの生成時に，領域を割り当てるコストが非常に少ない（選択の幅がない）</li>
</ul>
</li>
<li>欠点：
<ul>
<li>小規模の主記憶領域しか必要としないプロセスにとっては，利用しない領域まで割り当ての対象となり，結果としてOS全体で考えた場合の主記憶領域の使用効率が低下する。</li>
</ul>
</li>
</ul>
<p><strong>可変区画方式</strong>：</p>
<ul>
<li>プロセスは，必要な分だけ領域を要求</li>
<li>プロセスごとに要求サイズは異なる</li>
<li>要求があった分だけ割り当てる</li>
<li>問題点
<ul>
<li>空き領域の検索コスト
<ul>
<li>処理が進行するに従い，様々な大きさの空き領域が発生</li>
<li>新しいプロセスの要求に合う大きさの空き領域を探すコストが増大</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>断片化（フラグメンテーション）</strong>：</p>
<ul>
<li>プロセスからの要求サイズは異なるため，可変区画方式で眼持ちを割り当てると，プロセスが使えない大量の小さな領域が残ってしまう現象。</li>
<li>解決法：<strong>メモリコンパクション</strong>
<ul>
<li>メモリを確保しているプロセスの実行を止めた後に，断片化した領域を１つの連続した領域にまとめる。</li>
</ul>
</li>
</ul>
<p>可変区画方式における空き領域管理：</p>
<ul>
<li><strong>ベストフィット方式</strong>
<ul>
<li>割り当てた残り領域がもっとも少なくなる空き領域に割り当てる方式</li>
<li>一番効率的に見えるが</li>
<li>欠点
<ul>
<li>空き容量の探索コストが大きくなる場合がある</li>
<li>残った領域が小さすぎて他のプロセスが使用できない確率が高い</li>
</ul>
</li>
</ul>
</li>
<li><strong>ワーストフィット方式</strong>
<ul>
<li>割り当てた残り領域がもっとも大きくなる空き領域に割り当てる方式</li>
<li>残った領域は，ベストフィット方式より比較的大きくなる</li>
<li>欠点
<ul>
<li>処理が進むにつれ空き領域の大きさが均一化し，大きい要求に応じられない</li>
</ul>
</li>
</ul>
</li>
<li><strong>ファーストフィット方式</strong>
<ul>
<li>要求された量を確保できる最初に見つかった領域を割り当てる方式</li>
<li>探索コストが小さい。主記憶領域の全てを調べる必要がない</li>
<li>アドレス上位に大きい領域が残りやすくなり，大きい要求にも対応しやすい</li>
</ul>
</li>
</ul>
<h2 id="領域管理">領域管理</h2>
<h3 id="リスト方式">リスト方式</h3>
<table>
<thead>
<tr>
<th style="text-align:center">アドレス：A1</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">サイズ：S1</td>
</tr>
<tr>
<td style="text-align:center">next</td>
</tr>
</tbody>
</table>
<p>アドレス順リストの場合：ファーストフィット方式での検索が高速。<br>
大きさ順リストの場合：ベストフィット方式での検索が高速。</p>
<h3 id="ビットマップ方式">ビットマップ方式</h3>
<p>空き情報を示す配列</p>
<ul>
<li>ビットマップ
<ul>
<li>記憶領域を単位ブロックに分割
<ul>
<li>例：アドレスの上位数ビットが共通の部分など</li>
</ul>
</li>
<li>各領域に対応するビットを用意</li>
</ul>
</li>
<li>ビット配列により，主記憶全体の空き領域を表現
<ul>
<li>大きい連続した空き領域を検索する際は
<ul>
<li>フラグに０が続いている部分を探索</li>
</ul>
</li>
<li>各要素へのアクセスは高速だが，<strong>空き領域の検索コストが大きくなりがち</strong></li>
</ul>
</li>
</ul>
<h2 id="プログラムのロードと領域の再配置">プログラムのロードと領域の再配置</h2>
<p>プログラム記述から実行までの流れ：<br>
通常はリンケージエディタにおいてユーザがプログラム中に使ったライブラリ関数を結合し，即時実行可能形式（<strong>ロードモジュール</strong>）として，ファイルに格納されるとともに，実行時にはこのイメージのまま主記憶にロードされる。</p>
<p><strong>静的ライブラリ</strong></p>
<ul>
<li>リンク時にロードモジュールに<strong>埋め込み</strong>（静的リンク）</li>
<li>複数プログラムで使用されるライブラリがある場合，主記憶領域の無駄</li>
</ul>
<p><strong>共有ライブラリ</strong>：</p>
<ul>
<li>主記憶内にロードされた複数のプログラムから共有可能なライブラリ。</li>
<li>リンカはロードモジュールにライブラリの埋め込みを行わない。</li>
<li>共有ライブラリに対するリンク情報のみロードモジュールに書き込む</li>
<li>ロードモジュールは<strong>リンク情報のみ</strong>を持ち，<strong>実行時にリンク</strong>（ダイナミックリンク）</li>
<li>複数プログラムで使用される場合でも，各ライブラリは１つのイメージだけ主記憶上に存在すればよい</li>
<li>主記憶領域（およびディスク領域）の有効活用</li>
<li>共有ライブラリが<strong>リエントラント</strong>である</li>
</ul>
<p><strong>リエントラント性</strong></p>
<ul>
<li>複数のプログラム間で同一関数を共有するには，あるプログラムがその関数を実行中に中断された後，他のプログラムが同一関数を実行した後であっても，中断直後の状態から同一関すを再開できる必要がある。</li>
<li>複数のプログラムが主記憶上にロードされた変数を同時に利用可能な性質を<strong>リエントラント性</strong>(再入可能性)と呼ぶ。</li>
<li>各呼び出しごとに，作業領域を保存する仕組みが必要
<ul>
<li>関数内でグローバル偏すをアクセスしない。関数内でstaticな変数を使わないなど。</li>
</ul>
</li>
</ul>
<p><strong>実行時結合</strong>：実行時にリンク操作を行う</p>
<p><strong>リロケータブル（再配置可能）</strong>：プログラム本体が，主記憶上の任意の位置に配置（ロード）されても実行可能である性質。</p>
<ul>
<li>この場合，プログラム内の全てのアドレス指定が，プログラムの先頭のアドレスからの相対位置で表現されている必要がある。</li>
</ul>
<p><strong>共有ライブラリの現状</strong></p>
<ul>
<li>共有ライブラリは，主記憶の効率的利用という観点からは望ましい</li>
<li>しかし，プログラム（ライブラリ）全てがリエントラント性を満たすためには相当な書き換えが必要。</li>
<li>現状
<ul>
<li>ダイナミックリンク（単体）は，利用されている
<ul>
<li>２次記憶の有効利用</li>
<li>脆弱性対応時の容易性 =&gt;ライブラリだけを配布すれば良い（例　Windows　DLL）</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="オーバーレイ">オーバーレイ</h2>
<p>オーバーレイ</p>
<ul>
<li>指定した時刻に，アプリケーションのどの部分が主記憶上に存在すべきかをプログラマが指定する仕組み</li>
<li>毎に実行されたコード（親関数など）のうち，さしあたり(目前)必要のなくなったコードがロードされている主記憶領域に対して，新しく必要となったコードを上書き（overlay）できる</li>
<li>欠点
<ul>
<li>非常に複雑でエラーを起こしやすい</li>
<li>プログラマの負担が増大</li>
</ul>
</li>
</ul>
<p>軽量に仮想記憶を実装できるオーバーレイはIoTなどの分野で今後も重要な位置を占める</p>
<hr>
<p>1.マルチプログラミング環境では，プログラムの発生，消滅が頻繁に起こるため，プログラム（およびデータ）を格納する領域を管理する方式が重要となる。</p>
<p>2.メモリの割り当て方式には，あらかじめ決められたシステムで決めた大きさの領域を全てのプロセスに平等に割り当てる<strong>固定区画方式</strong>と，プロセスが要求する大きさの領域を与える可変区画方式がある。</p>
<p>3.可変区画方式において，もし適切な管理を行わないと，プロセスが使えない断片的なメモリ領域が数多く発生する<strong>メモリフラグメンテーション</strong>が起こる。</p>
<p>4.空き領域を管理する方法として，リストデータ構造を用いるリスト方式と，配列を用いる<strong>ビットマップ方式</strong>がある。また，割り当て方式として，<strong>ベストフィット方式</strong>，<strong>ファーストフィット方式</strong>，<strong>ワーストフィット方式</strong>がある。</p>
<p>5.マルチプログラミング環境では，主記憶を効率よく利用するために，複数のプログラムが，主記憶中にロードされたライブラリを共有できる<strong>共有ライブラリ</strong>が有効な手法である。共有ライブラリを実現するためには，プログラムのリエントラント性，およびプログラムの実行時にライブラリを結合する<strong>ダイナミックリンク</strong>が必要である。</p>
<p>6.プログラマが明示的にプログラムの主記憶へのロードを管理し，現在実行している部分のみを主記憶にロードすることにより，プログラムの実行に必要な主記憶量を提言する方法を<strong>オーバーレイ</strong>と呼ぶ。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[OS：主記憶管理基礎]]></title>
        <id>https://zy080080.github.io/post/u3Uh6KrGp/</id>
        <link href="https://zy080080.github.io/post/u3Uh6KrGp/">
        </link>
        <updated>2021-01-17T09:24:20.000Z</updated>
        <summary type="html"><![CDATA[<p>教科書第7章　まとめ</p>
]]></summary>
        <content type="html"><![CDATA[<p>教科書第7章　まとめ</p>
<!-- more -->
<p><strong>物理アドレス空間</strong>：主記憶上の実アドレス空間。</p>
<p><strong>論理アドレス空間</strong>：プログラムからみた，各プロセスごとに独立した実アドレス空間に対応するアドレス空間。</p>
<p><strong>主記憶管理部</strong>(memory management unit：<strong>MMU</strong>)：各プロセスごとの論理アドレス空間を一次元アドレスで表現されている受寄屋上の物理アドレス空間へ変換（Mapping）を行うハードウェアである。</p>
<p><strong>ネーミング関数</strong>：</p>
<ul>
<li>変数，定数などの識別子を論理アドレスに変換する関数</li>
<li>コンパイル・リンク時に行われる</li>
</ul>
<p><strong>メモリ関数</strong>：</p>
<ul>
<li>論理アドレスから物理アドレスに変換する関数。</li>
<li>OSによって行われる</li>
</ul>
<p><strong>内容関数</strong>：</p>
<ul>
<li>物理アドレスから，そのアドレスに格納された内容に変換する関数</li>
<li>ハードウェアによって行われる</li>
</ul>
<p><strong>下限レジスタ</strong>：主記憶上のOS領域とユーザ領域の境界を示すレジスタである。</p>
<p>下限レジスタ機構とその問題点：</p>
<ul>
<li>ユーザ領域の下限を設定
<ul>
<li>下限レジスタが示す境界でOS/ユーザ領域を区別</li>
</ul>
</li>
<li>問題点
<ul>
<li>領域境界が１つしかない</li>
<li>OS領域を保護することしかできない</li>
<li>複数のプロセス間でアクセス権は設定できない</li>
</ul>
</li>
</ul>
<p>そのため，任意・複数の境界を設定し，プロセスごとにアクセス権を設定したい。 -&gt;ロック/キー機構</p>
<hr>
<p>1.<strong>主記憶管理</strong>の目的は，ユーザに独立した仮想アドレス空間を提供することである。理想的な仮想アドレス空間を持つべき特徴としては，大きさ無制限，プロセスごとに固有，プロセス間で主記憶空間を共有可，プログラム部，データ部，スタック部など複数の１次元アドレスがある。</p>
<p>2.<strong>下限レジスタ機構</strong>は，ユーザ領域とオペレーティングシステム領域を下限レジスタが示す位置で分離し，CPUの実行モードにより，オペレーティングシステム領域へのアクセスを制限する基本的な仕組みである。</p>
<p>3.<strong>ロック/キー機構</strong>は，アドレスを論理的に上位と下位に分け，上位部の内容を主記憶を示すアドレスとしてだけでなく，主記憶ブロックへのアクセス権が格納されているロックデータ配列への添字（ポインタ情報）として用いる。この考え方は，ページング，セグメンテーションによるメモリ管理の基礎である。<br>
　現在実行中のプロセスの主記憶に対するアクセス権がPSWに格納されていて，それをキー部に対応するロックデータと比較して，アクセスを許可するかどうかを決める。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[OS：並行プロセス-モニタ]]></title>
        <id>https://zy080080.github.io/post/ECsYYoE6u/</id>
        <link href="https://zy080080.github.io/post/ECsYYoE6u/">
        </link>
        <updated>2021-01-16T12:08:05.000Z</updated>
        <summary type="html"><![CDATA[<p>教科書第6章 まとめ</p>
]]></summary>
        <content type="html"><![CDATA[<p>教科書第6章 まとめ</p>
<!-- more -->
<p>モニタとセマフォ</p>
<table>
<thead>
<tr>
<th style="text-align:center">セマフォ</th>
<th style="text-align:center">モニタ</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">P命令</br>共有リソースの取得トライ。失敗時に待ち行列へ</td>
<td style="text-align:center">wait()</br>待ち行列へ</td>
</tr>
<tr>
<td style="text-align:center">V命令</br>共有リソース返却，待ちプロセスを１つ実行可能状態へ</td>
<td style="text-align:center">signal()（Javaではnotify()）</br>待ちプロセスを１つ実行可能状態へ</td>
</tr>
<tr>
<td style="text-align:center">-</td>
<td style="text-align:center">queue()</br>待ちプロセスの有無を返す</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:center">セマフォ</th>
<th style="text-align:center">モニタ</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">P命令を実行しないとセマフォの状態がわからない</td>
<td style="text-align:center">メソッドにより，共有リソースの状態を排他的に調べられる</td>
</tr>
<tr>
<td style="text-align:center">リソースを取ろうとしないと，空いているかどうか不明</td>
<td style="text-align:center">リソースの空きの確認とリソース待ちが分離</td>
</tr>
<tr>
<td style="text-align:center">取れなかったら，いきなり待ち行列に待たされる</td>
<td style="text-align:center">条件変数へのwaitにより，自由度の高い「待ち」が可能</td>
</tr>
</tbody>
</table>
<p><strong>モニタの利点（セマフォに対し）</strong>：</p>
<ul>
<li>リソース確認と「待ち」状態の分離
<ul>
<li>リソースに空きがない場合，「待ち」に入るかどうか自由に選べる</li>
</ul>
</li>
<li>排他制御すべきリソースの明示
<ul>
<li>モニタ内に記述されるため明示的</li>
<li>他の一般的な変数と判別しやすい</li>
<li>排他的メソッドを通じた処置により保護</li>
</ul>
</li>
<li>プログラマに安全で扱いやすい枠組みを提供</li>
</ul>
<hr>
<p>1.<strong>モニタ</strong>とは，オブジェクト思考の考え方を排他制御（およびプロセス同期）に適用した解法である。モニタ内には，排他制御の対象となる<strong>リソース</strong>，リソースを操作するための<strong>メソッド</strong>，オブジェクトの実体を生成する際に実行する<strong>初期コード</strong>，<strong>終了時コード</strong>が存在する。</p>
<p>2.モニタ内のリソースは，メソッドを介してのみアクセス可能である。また，各モニタのメソッドは排他的に実行される。したがって，プログラマはモニタ内のリソースの排他制御を考慮する必要はない。</p>
<p>3.モニタを用いることにより，セマフォよりもさらに抽象度が高くできるとともに，デッドロックの可能性のある処理を，コンパイラで実行前にある程度事前に検出することも可能となる。</p>
<p>複数のプロセスが，同時に実行されている場合，共通のリソース（共有変数など）にアクセスする場合は（排他制御）が必要となる。また，（排他制御）が必要となる領域のことを（クリティカルセクション）と呼ぶ。（排他制御）の解決方法の代表的な例は（セマフォ）である。これは，待ち行列と整数変数を持つデータ構造であり，（P）命令と（V）命令により制御する。一般的には，（クリティカルセクション）に入る前に（P）命令を，出る前に（V）命令を実行する。さらに，より抽象度の高い（排他制御）の方法として，（モニタ）がある。（モニタ）は，（排他制御）の対象となるリソースを（オブジェクト）指向の枠組みで抽象化したモデルである。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[OS：並列プロセス-セマフォ]]></title>
        <id>https://zy080080.github.io/post/oEPtkexau/</id>
        <link href="https://zy080080.github.io/post/oEPtkexau/">
        </link>
        <updated>2021-01-16T04:50:30.000Z</updated>
        <summary type="html"><![CDATA[<p>教科書第5章　まとめ</p>
]]></summary>
        <content type="html"><![CDATA[<p>教科書第5章　まとめ</p>
<!-- more -->
<p><strong>semaphore　セマフォ</strong>：整数型の変数（セマフォ変数）と，待ち行列からなるデータ構造を有する構造体である。この構造体へは，P命令，V命令の２つの操作が許されている。</p>
<p><strong>P命令</strong>：リソースを要求し，許可されない場合は待ち状態へ移行。</p>
<ul>
<li>空きリソースを1つ使用</li>
<li>空きリソース数（セマフォ変数）をデクリメント</li>
<li>空きがない場合，プロセスを待ち状態に</li>
</ul>
<p><strong>V命令</strong>：リソースを解放し，待ちプロセスを実行可能状態へ移行。待ちプロセスがない場合，空きリソース数をインクリメント。</p>
<ul>
<li>空きリソースを1つ解放</li>
<li>待ちプロセスを1つ実行可能状態に</li>
<li>待ちプロセスがない場合，空きリソース数（セマフォ変数）をインクリメント</li>
</ul>
<p><strong>デッドロック</strong>：全てのプロセスが，あるリソースを確保するために，別のリソースを確保したママ解放を待っている状態となってしまい，これらのリソースに関連する全てのプロセスの実行が止まってしまう状態。</p>
<p><strong>ダイニングフィロソファの解法</strong>：</p>
<ul>
<li>解法1：フォーク一本一本ではなく，「フォーク全体を使う権利」をセマフォで管理
<ul>
<li>うまくいくが，同時に一人しか食事できない。</li>
<li>実際は二人同時に食事可能な場合があるはず</li>
<li>リソースが有効利用できていない</li>
</ul>
</li>
<li>解法2：１つのプロセスだけが逆順でフォークを要求
<ul>
<li>うまくいくが，哲学者4が特殊であるため，<strong>公平性</strong>を欠いている可能性がある</li>
</ul>
</li>
<li>解法3：少し我慢をする哲学者
<ul>
<li>右のフォークを確保後，左のフォークが確保できなければ，一旦右のフォークを解放して少し待つ</li>
<li>これにより，「全員右フォークを確保した状態」から抜け出せる</li>
<li>問題点：全員が同時に「右フォーク確保，右フォーク解放」を繰り返すと，デッドロック。</li>
</ul>
</li>
<li>解法4：不定時間だけ我慢をする哲学者
<ul>
<li>右のフォークを確保後，左のフォークが確保できなければ，一旦右のフォークを解放して少し待つ</li>
<li>待つ時間はランダムに決定する</li>
<li>これによって，全員が同時に「右のフォークを確保，右のフォークを解放」を繰り返すことがなくなる</li>
<li>問題点：デッドロックが発生しないことを証明できない。フォークを解放して「譲った」哲学者は，次に優先される仕組みがないと公平性に欠ける。</li>
</ul>
</li>
<li>理想的な解法：
<ul>
<li>リソース確保に失敗した場合，当該リソースを確保するための<strong>待ち行列に並ぶことができる</strong>こと</li>
<li>全てのプロセスがリソースを<strong>平等に確保できる</strong>ことを保証すること</li>
</ul>
</li>
</ul>
<hr>
<p>1.<strong>P命令</strong>(wait)と<strong>V命令</strong>(signal)からなる<strong>セマフォア</strong>は，より抽象的な排他制御の仕組みとして開発された。セマフォを獲得できないプロセスは，待ち状態に移行するため，ビジーウェイティングの問題はない。</p>
<p>2.プロセス間通信や計算機間の通信(Local Area Network, Internetwork)をモデル化した<strong>プロデュサ/コンシューマ問題</strong>や，データベースアクセス制御をモデル化した<strong>リーダタイム問題</strong>は，非同期問題の解法として重要な例題である。</p>
<p>3.<strong>食事をする哲学者問題</strong>は，複数リソースを獲得する際のデッドロックをモデル化している。複数リソースを獲得するプログラムを作成する場合，常にデッドロックを考慮する必要がある。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[OS：並列プログラム-排他制御基礎]]></title>
        <id>https://zy080080.github.io/post/7nRN9HqLl/</id>
        <link href="https://zy080080.github.io/post/7nRN9HqLl/">
        </link>
        <updated>2021-01-16T02:33:25.000Z</updated>
        <summary type="html"><![CDATA[<p>教科書第4章　まとめ</p>
]]></summary>
        <content type="html"><![CDATA[<p>教科書第4章　まとめ</p>
<!-- more -->
<p><strong>プロセス協調</strong>：仕事の分担や通信など，複数プロセスが助け合う。</p>
<ul>
<li>プロセス間通信のための仕組み：通信バッファ
<ul>
<li>通信バッファがないと，送信側と受信側でタイミングを合わせる必要があり，受信側は，常にメッセージが来ないかをチェックしていなければならない。</li>
<li><strong>通信バッファの役割：通信バッファは，通信情報を一時的に保存する機能である。全てのプロセスからアクセスできる領域に存在し，送信側からみた場合，受信側プロセスの状態に関わらず，常時送信データを書くことが可能であり，また受信側プロセスからみた場合，常時受信データを通信バッファから読み込むことが可能である</strong>。</li>
<li>受信すべきメッセージがバッファ内に存在するか否かをフラグで判断
<ul>
<li>フラグが立っている間，送信側は新たに送信を行わない-&gt;上書き回避。</li>
<li>フラグが降りている間，受信側は新たに順を行わない-&gt;再受信回避。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>プロセス競合</strong>：複数プロセスで有限リソースを取り合う。調停し，各プロセスに適切にリソース割り当て。</p>
<ul>
<li>プロセス間での命令実行順に起因する矛盾
<ul>
<li>変数から値を読んで，変数に値を書くまでの間に，他のプロセスが変数を読んでしまう。
<ul>
<li>他のプロセスからみて，変数は変化していない。</li>
<li>実際は変化させるための手続きが始まっている。</li>
</ul>
</li>
</ul>
</li>
<li>解決するには，
<ul>
<li>共有変数の内容をレジスタ内に読み込み，演算をし，結果を共有変数に格納する一連の処理の実行において，3命令を分解できないような制御が必要。</li>
<li><strong>クリティカルセクション</strong>：このような分割してはいけない一連の処理。</li>
<li><strong>排他制御(mutual exclusion)</strong>：クリティカルセクションなどを他のプロセスと排他的に実行するための制御。</li>
</ul>
</li>
</ul>
<p><strong>プロセス干渉</strong>：他のプロセス影響で異常が発生すること。原因はプログラムのバグ。</p>
<h2 id="排他制御">排他制御</h2>
<p>クリティカルセクションなどを他のプロセスと排他的に実行するための制御。</p>
<p>重要な性質</p>
<ul>
<li>即時性
<ul>
<li>クリティカルセクションの実行に競合するプロセスが他にない場合，プロセスはクリティカルセクションの実行を直ちに許可される。</li>
</ul>
</li>
<li>デッドロック防止
<ul>
<li>競合するプロセスがある場合でも，許可されるまで永久に待たされてはいけない。</li>
</ul>
</li>
<li>公平性
<ul>
<li>どのプロセスも，他のプロセスがクリティカルセクションを実行することを防げられない。</li>
</ul>
</li>
</ul>
<p><strong>エントリーシーケンス</strong>：クリティカルセクジョンに入る権利を獲得する一連の処理。<br>
<strong>イグジットシーケンス</strong>：クリティカルセクションから出るための処理。</p>
<p>フラグによる制御：</p>
<ul>
<li>クリティカルセクションに入ろうとするプロセスは，フラグを確認し，入れるかどうかを決定。</li>
<li>入ると同時にフラグを下げる</li>
<li>以上の２つの処理自体が分割できない操作である。</li>
</ul>
<h2 id="dekkerのアルゴリズム">Dekkerのアルゴリズム</h2>
<p>２プロセスの排他制御を行うことを可能する。</p>
<p><strong>Interest</strong>：</p>
<ul>
<li>プロセスA，Bがクリティカルセクションに興味があるか否かを示す。</li>
<li>まずクリティカルセクションに入る前に，クリティセクションに入りたい皆を宣言。競合者がいなければ入れる。</li>
</ul>
<p><strong>Priorityt</strong>：</p>
<ul>
<li>プロセスA，Bがクリティカルセクションに同時に興味を持った場合，どちらを優先するかを決定する。</li>
<li>自分に優先度が回ってくるまでInterest状態を解除。</li>
</ul>
<p>ポイント：</p>
<ul>
<li>入る前に手を挙げる。</li>
<li>優先権により競合を解決。</li>
</ul>
<p><strong>問題点</strong>：</p>
<ul>
<li>ユーザプログラムに依存
<ul>
<li>ちゃんとプロセスが約束を守ってくれないと破綻。</li>
</ul>
</li>
<li><strong>ビジーウェイト（busy　wait）</strong>
<ul>
<li>一方がクリティカルセクションを実行中，待っている方は優先権をひたすらチェックし続ける-&gt;CPUリソースの無駄。</li>
</ul>
</li>
<li>最近はメニューコアが主流。CPUリソースが余っているためビジーウェイトが必ずしも悪ではない状況が発生
<ul>
<li><strong>ビジーウェイトの利点</strong>
<ul>
<li><strong>リソースが空いた時の反応が早い</strong></li>
<li>スピンロック</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="割り込み制御による排他制御">割り込み制御による排他制御</h2>
<p>単一プロセッサシステムの場合，</p>
<ul>
<li>割り込みのみがプロセス中断を発生させる
<ul>
<li>エントリシーケンスで，割り込み禁止命令を実行しておけば良い</li>
<li>同様にイグジットシーケンスで割り込み禁止を解除</li>
</ul>
</li>
<li>ただし
<ul>
<li>割り込み禁止時間の増加はシステムの性能に影響</li>
<li>OS実行の自由度が少なくなり，応答時間が増加。</li>
<li>長時間割り込みが禁止された場合，入出力要求への対応ができなくなり，OSが停止する可能性がある。</li>
</ul>
</li>
</ul>
<h2 id="ハードウェアによる排他制御">ハードウェアによる排他制御</h2>
<p>対話処理の重要性から排他制御の必要性が認識される</p>
<p><strong>テストアンドセット命令</strong>：</p>
<ul>
<li>ハードウェア自体に，排他制御のための仕組みを</li>
<li>v = test_and_set(x)
<ul>
<li>v = x と x = 0を同時に実行する命令</li>
</ul>
</li>
<li>競合者フラグのチェックとセットを同時に行える。</li>
<li><strong>２つの変数に同時に作用することにより，非常に少ないソフトウェアの実行コストでの排他制御が実現可能になった。</strong></li>
</ul>
<hr>
<p>1.複数のプロセスを同時に実行する環境においては，<strong>プロセス競合</strong>，<strong>プロセス協調</strong>が重要となる。これらの解決には，プロセス間の同期手法が基本となる。</p>
<p>2.プログラムが中断されることにより，プロセス競合が起こる可能性のあるプログラム領域を<strong>クリティカルセクション</strong>と呼ぶ。クリティカルセクション実行中は，他のプロセスが同時にクリティカルセクションに入らないように**排他制御(MUTEX)**を行う必要がある。</p>
<p>3.ソフトウェアによる排他制御の基本的な手法として，Dekkerのアルゴリズムがある。しかし，このアルゴリズムの問題点としては<strong>ビジーウェイテイング</strong>がある。</p>
<p>4.クリティカルセクションの前後で割り込みを禁止することによる排他制御の実現手法は，システムの性能に影響を及ぼす場合が多いので，できる限り利用は避けるべきである。</p>
<p>5.排他制御を実現するためのハードウェア支援として**テストアンドセット（TS）**命令が開発され，現在でも排他制御のための基本命令である。</p>
<p>4.1 排他制御を行う手法として，割り込み禁止命令を用いる方法がある。この方法の利点と欠点を挙げよ。<br>
　利点：プログラミングが容易である。欠点：長時間の割り込み禁止はシステム性能の低下につながる。</p>
<p>4.2 排他制御を実現するための命令追加について，TS命令がSWAP命令に比べて容易に実現できることを示せ。<br>
　SWAP命令は，２つのレジスタを交換するため。以下のような命令操作が必要となる。<br>
TEMP    &lt;-  R1<br>
R1      &lt;-  R2<br>
R2      &lt;-  R1<br>
　これは。CPU内で3回のデータ転送が必要であることを示している。現在はデータ転送を1回とするRISCアーキテクチャが主流のため，容易に実装することは困難であり，3回のデータ転送を1命令で行う専用回路が必要となる。<br>
　一方，TS命令の命令操作は以下である。<br>
R2 &lt;-   R1<br>
R1 &lt;-   &quot;0&quot;<br>
　１行目は通常のレジスタ転送であり，CPUのハードウェア拡張は必要としない。さらに，0をレジスタに代入するのはGNDレベルを用いて代入操作ができるため，データ転送のための特別な回路も必要としない。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[OS：CPUの仮想化ースケジューリング]]></title>
        <id>https://zy080080.github.io/post/RWPOSZYfW/</id>
        <link href="https://zy080080.github.io/post/RWPOSZYfW/">
        </link>
        <updated>2021-01-14T06:48:50.000Z</updated>
        <summary type="html"><![CDATA[<p>教科書第3章　まとめ</p>
]]></summary>
        <content type="html"><![CDATA[<p>教科書第3章　まとめ</p>
<!-- more -->
<h2 id="プロセス中断方式">プロセス中断方式</h2>
<p><strong>プリエンプション方式</strong>：OSが実行中のプロセスの実行権を強制的に取り上げることにより，プロセスを中断させる方式。（Windows　XP以降，UNIX，Mac OSなど）</p>
<p><strong>ノンプリエンプション方式</strong>：OSではなく，実行中のプロセスが自主的にCPUリソースをOSに戻す方式。この方式によるマルチタスク（マルチプログラミング）の実装は容易であるが，もしプログラムの暴走により，自発的なCPUリソースの返還がない場合は，<strong>システムの停止に繋がる</strong>。</p>
<h2 id="スケジューリングの目的">スケジューリングの目的</h2>
<p>リソースを効率的に利用するために，効率の良いスケジューリングが必要。</p>
<p>スケジューリングアルゴリズムの効率化の指標：</p>
<ul>
<li><strong>応答時間</strong>
<ul>
<li>その定義は，対象処理がバッチ処理か対話処理かどうかで異なる。
<ul>
<li>バッチ処理の場合，ジョブが投入してから結果を受け取るまでの時間と定義され，<strong>ターンアラウンドタイム</strong>とも呼ばれる。</li>
<li>対話処理の場合，端末から命令を入力した後に，コンピュータシステムから結果を受け取るまでの時間と定義され，<strong>レスポンスタイム</strong>とも呼ばれる。</li>
</ul>
</li>
</ul>
</li>
<li><strong>スループット</strong>
<ul>
<li>単位時間に行われるユーザに有益な仕事量。ただし，プロセスを切り替えるときのオーバーヘッドなど，ユーザの仕事に直接関係しない仕事は仕事量に含まれない。</li>
</ul>
</li>
</ul>
<p>応答時間とスループットは相反することもある。例えば，レスポンスタイムを向上させるためには，対話処理を実行するプロセスに，非常に短い間隔でCPUリソースを与えるようなスケジューリングアルゴリズムが有効である。しかし，このようにクオンタムの非常に小さいスケジューリング手をスループットの面から見た場合，頻繁なプロセス切り替え操作はオーバーヘッドの増加に繋がる。<br>
一方，スループットを向上させるためには，入出力操作やコンテキスト切り替えなど，オーバーヘッドの対象となるような操作をできる限り排除し，計算処理そのものにCPUリソースを用いることが有効となる。</p>
<p><strong>応答時間向上を追求-&gt;対話型処理を優先的に-&gt;TSSクオンタムを短く-&gt;切り替え回数増加，切り替えオーバーヘッド増加-&gt;スループット低下</strong></p>
<h2 id="様々なスケジューリング方式">様々なスケジューリング方式</h2>
<p><strong>FIFO(First In First Out)到着順スケジューリング，FCFS(First Come First Served)</strong>：</p>
<ul>
<li>特徴：
<ul>
<li>単純：プロセス選択機構も簡単になるし，選択オーバーヘッドも小さい</li>
<li>公平：追い抜き禁止</li>
</ul>
</li>
<li>欠点：ターンアラウンドタイムはよくない
<ul>
<li>待ち行列が100s,1s,1s,1sの時平均待ち時間27s</li>
<li>待ち行列が1s,1s,1s,100sの時平均待ち時間102s</li>
</ul>
</li>
</ul>
<p><strong>SPTF(Shortest Processing Time First)処理時間順スケジューリング</strong>：</p>
<ul>
<li>待ち行列内プロセスを処理時間順でソート</li>
<li>特徴：応答時間最短，理想的</li>
<li>欠点：実装不可能，各プロセスの処理時間を事前に知ることができない。
<ul>
<li>経験則（heuristic）から近似的に処理時間を求める。</li>
<li>近似実装：すでに実行した時間から。入出力処理から。</li>
</ul>
</li>
<li>亜種：残り処理時間順（SRTF）</li>
</ul>
<p><strong>PS(Priority Scheduling)優先度順スケジューリング</strong>：</p>
<ul>
<li>各プロセスに優先度を付加
<ul>
<li><strong>静的優先度</strong>：プロセス生成時に指定した優先度を使用。
<ul>
<li>例：プロセスの種類ごとに優先度を規定。リアルタイムプロセス&gt;OS&gt;対話型&gt;バッチ</li>
</ul>
</li>
<li><strong>動的優先度</strong>：プロセス実行中に優先度を適宜変化
<ul>
<li>例：既実行時間に応じて優先度を変化。入出力操作直後のプロセスの優先度を高く。</li>
</ul>
</li>
</ul>
</li>
<li>利点：優先度を適切に設定できれば非常に有効。</li>
<li>欠点：高負荷時，優先度の低いプロセスがなかなか実行権を獲得できない（starvation）-&gt;<strong>待ち時間に応じた優先度変化(agingエージング)などで対処</strong>。</li>
</ul>
<p><strong>RR(Round Robin)ラウンドロビン</strong>：</p>
<ul>
<li>TSSで用いられる方式。</li>
<li>待ち行列から選択されたプロセスに，微小なCPU利用時間（クオンタム）を割り当て。</li>
<li>クオンタム-&gt;無限大：RR＝FIFO</li>
<li>クオンタム＝極小：処理時間の短いプロセスに有利</li>
</ul>
<p><strong>MLF(Muti-Level Feedback)多重レベルフィードバック</strong>：</p>
<ul>
<li>Multi-Level Feedback (from Multics Project)
<ul>
<li>優先度別に待ち行列を用意。</li>
<li>プロセスは，クオンタムを得るごとにより優先度の低い待ち行列に移される。</li>
</ul>
</li>
<li>Multi-Level Feedback
<ul>
<li>複数のクオンタムを必要とするようなプロセス（すなわち長い時間がかかるプロセス）は，どんどん優先度が下がってゆく。</li>
<li>SPTFの良い近侍になっている。</li>
</ul>
</li>
</ul>
<hr>
<p>1.CPUスケジューリングには，<strong>到着順スケユーリング</strong>，<strong>処理時間順スケジューリング</strong>，<strong>優先度順スケジューリング</strong>，<strong>ラウンドロビン(Round-Robin)スケジューリング</strong>，<strong>多重レベルフィードバックスケジューリング</strong>などの方式があり，OSが用いられる環境によって様々なスケジューリングが適用されている。スケジューリング自体，１秒間に数十から数百回行う処理であり，スケジューリングの効率とともに，高速性も同時に要求される。</p>
<p>2.<strong>処理時間順スケジューリング</strong>は，理論上応答時間を最小にすることが知られている。しかし，プロセスの処理時間を，実行前に知ることは不可能である。そこで，既実行時間の少ないプロセスは，処理時間も少ないという経験的な法則を用い，近似的な処理時間順スケジューリングが用いられる。</p>
<p>3.優先度には，プロセスの生成時に決まる<strong>静的優先度</strong>と，実行中に変化する<strong>動的優先度</strong>がある。通常の対話処理では，この２つの優先度を用いてスケジューリングする場合が多い。優先度スケジューリング時には，スタベーションの問題を解決するためにエージングが併用されることが多い。</p>
<p>3.1 次の文の括弧を埋めよ（下線部の後では下線部の意味に対応する言葉を書くこと）<br>
　プロセスのスケジューリング手法の一例として，残り処理時間順(SPT)スケジューリングがある。これは処理時間の短いプロセスから順に実行する方式であり，理論上は応答時間を最小にすることができる。この方式ではあるプロセスが実行中でも，より処理時間の短いプロセスが入ってきた場合には，（実行中のプロセスはオペレーティングシステムにより中断）（<strong>プリエンプション</strong>）される。<br>
　優先度スケジューリングにおいては，優先度の低いプロセスになかなか実行権が回ってこない場合がある。この現象を（スタベーションstarvation）と呼び，通常（<strong>エージング</strong>）を併用することより回避する。</p>
<p>3.2 リアルタイム処理に用いられるデッドラインスケジューリングについて調べよ。<br>
　プロセスの実行に終了目標時間（deadline）を設定し，目標時間に近づくと，プロセスの優先度を上げて該当プロセスにCPUリソースが配分されやすいようにするスケジューリング。この方式だけでは処理のリアルタイム性を厳密に保証することは困難であるが，近似的な実装手法としてよく用いられる。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[OS：CPUの仮想化ープロセス]]></title>
        <id>https://zy080080.github.io/post/OENVD2_g7/</id>
        <link href="https://zy080080.github.io/post/OENVD2_g7/">
        </link>
        <updated>2021-01-14T00:09:26.000Z</updated>
        <summary type="html"><![CDATA[<p>教科書第二章まとめ</p>
]]></summary>
        <content type="html"><![CDATA[<p>教科書第二章まとめ</p>
<!-- more -->
<p></p>
<p>プロセス：ユーザの代わりにOSに対してリソースを要求するとともに，リソースの割り当てを受ける単位。システムが処理する仕事の単位。</p>
<p>プロセス処理形態</p>
<ul>
<li>ユニプロセッサ・ユニプログラミング方式
<ul>
<li>１つのCPUに対して１つのプロセス</li>
<li>バッチ処理</li>
</ul>
</li>
<li>ユニプロセッサ・マルチプログラミング方式
<ul>
<li>１つのCPUに対して複数のプロセス</li>
<li>TSS（Time　Sharing　System　時分割処理方式）</li>
</ul>
</li>
<li>マルチプロセッサ・マルチプログラミング方式
<ul>
<li>複数のCPUに対して複数のプロセス</li>
<li>並列・分散処理</li>
</ul>
</li>
</ul>
<p><strong>同時実行できるプロセス数よりCPUが多いとCPUが遊んでいてもったいないため，プロセスをさらに小さい単位に分割。</strong></p>
<p><strong>スレッド</strong>：CPUリソースが割り当てられる論理単位。</p>
<ul>
<li>CPUリソースをスレッドごとに割り当て</li>
<li>プログラムの実行においては，スレッドは１つの命令の流れとしてとらえることができる。</li>
<li>利点
<ul>
<li>TSSによる切り替えオーバヘッドが軽い
<ul>
<li>同一プロセスから生成されてるから<strong>メモリ領域が同じ</strong>。</li>
<li>メモリ使用量は<strong>1プロセス分</strong>で済む。</li>
<li><strong>別名：Light Weight Process</strong></li>
<li>マルチスレッドの場合，各スレッドは，独自にレジスタ群とスタックを持つともに，CPUリソースのwリアて単位となる。その他，プロセス内で管理される主記憶，プログラム領域，静的変数領域，動的変数領域，PSWなどが，各スレッド間で共有される。また，ファイル情報をプロセス単位で管理されるため，スレッドの生成が軽量（早い）である。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>プロセスとスレッドの違い：</p>
<ul>
<li>プロセス
<ul>
<li>Microsoft Word</li>
<li>Microsoft Excel</li>
<li>各プログラムはプロセスとして処理</li>
</ul>
</li>
<li>スレッド
<ul>
<li>Wordの場合，印刷，編集など，同じ『Word』というプログラムの中で<strong>同時（並行）動作できる単位</strong>                                                                                           |<br>
<strong>イベント</strong>：CPU内での通常の計算処理以外の事象。</li>
</ul>
</li>
</ul>
<p><strong>インターバルタイマー</strong>：TSSで用いる一定時間ごとに決まったイベントを発生させるための装置。</p>
<ul>
<li>TSSでは，定期的な切り替えが必要。インターバルライマが定期的に割込みを発生することで切り替えを実現する。</li>
</ul>
<p><strong>割込み</strong>：通常のCPU演算動作とは異なる事象のこと。</p>
<ul>
<li>キーボード入力を受け取ったなど</li>
<li>割込み発生時にプロセスの切り替えが起こる。</li>
</ul>
<p><strong>割込み処理</strong>：割り込みが発生した時に，CPUには非常に高速かつ軽量に処理するプログラムを実行可能なプログラム実行方式。</p>
<ul>
<li>内部割り込み
<ul>
<li>スーパバイザコール割込み</li>
<li>プログラムチェック（例外）割込み</li>
<li>実行中のプログラムを発生原因とする</li>
<li>プログラム自体の異常など</li>
</ul>
</li>
<li>外部割り込み
<ul>
<li>入出力割込み</li>
<li>タイマ割込み</li>
<li>マシンチェック割込み（冷却装置の異常，電源装置の異常など）</li>
<li>リスタート割込み</li>
<li>その他の要因で発生する</li>
<li>ほかの優先的処理からの要求，ハードウェア異常など</li>
</ul>
</li>
</ul>
<p><strong>スーパバイザモード</strong>：OSを実行するモードであり，CPUが有する全ての命令とOSが管理する全てのリソース扱うことが可能。</p>
<p><strong>ユーザモード</strong>：ユーザの作成した応用プログラムを実行するモードであり，実行できる命令や利用できるリソースに制限がある。</p>
<p><strong>スーパバイザコール割込み</strong>：ユーザプログラムがOSに対して処理を依頼する際に発生する割込み。</p>
<ul>
<li>この時にCPUの実行モードが切り替わる</li>
</ul>
<p><strong>例外割込み（プログラムチェック割込み）</strong>：実行中のプログラムで以上が起こった時に発生する割込み。</p>
<p><strong>割込み処理ルーチン</strong>：割込みハンドラ，割込み処理プログラム。</p>
<p><strong>PSW(Program Status Word)プログラム状態語</strong>：CPU内のプロセスの再開必要なレジスト情報。</p>
<ul>
<li>プログラムカウンタの値</li>
<li>スタックレジスタの値</li>
<li>汎用レジスタの値</li>
<li>割込みマスク（割り込みを禁止すること）の値など</li>
</ul>
<p><strong>PCB(Process Control Block)プロセス制御ブロック</strong>：メモリ上の，PSWを待避するための領域。</p>
<ul>
<li>プロセス識別子　各プロセスに割当てられる一連の番号</li>
<li>PSW　中断時に伝送されたPSW情報</li>
<li>ユーザ名　プロセスの所有者</li>
<li>実行優先度　プロセスに与えられている実行優先度</li>
<li>既実行時間　プロセスがすでにCPUリソースを消費した時間。実行優先度とともに，スケジューリングに用いる。</li>
<li>リソース情報　プロセスの確保しているリソース情報</li>
</ul>
<p><strong>割込みベクタ</strong>：割込みの種類に対応する数字（ID）<br>
割込み処理ルーチン内では，割込みの種類を解析し，その割込みの種類に応じた処理ルーチンを実行する</p>
<p><strong>割込みベクタテーブル</strong>：割込み処理ルーチンは，あらかじめ処理の内容に応じて，実行する処理の番地をテーブル化したもの。<strong>処理の高速化を図る</strong>。<br>
割込み処理ルーチンはメインメモリ上にある割込みベクタテーブルと，システムバス上の割込みベクタ番号から，次に実行するアドレスを迅速に決定する。</p>
<p><strong>実行状態（running）</strong>：プロセスを実行している状態。リソースは，そのプロセスのために確保されている。</p>
<p><strong>実行可能状態（ready）</strong>：実行できるが，CPUリソースが確保できていない状態。CPUリソースを確保した時点で実行開始される。</p>
<p><strong>待ち状態（waiting）</strong>：CPU以外のリソースも確保できていない状態。入力待ちなどもこれに含まれる。</p>
<hr>
<p>1.プロセスの中断，再開は，<strong>割り込み</strong>により行う。割り込みが発生した場合，オペレーティングシステムは，<strong>割込み処理ルーチン</strong>にただちに処理を切り替える。割込み処理ルーチン内で，まず実行中のPSWを主記憶内に伝送し，次にCPUスケジューラを起動させ，そして実行するプロセスを選ぶ。最後に，実行するプロセスのPSWをCPU内に伝送することにより，新しいプロセスを再開する。これら一連の処理を<strong>コンテキスト切り替え</strong>と呼ぶ。</p>
<p>2.OS内におけるプロセスは，全ての実行に必要なリソースを獲得して実行中の<strong>実行状態</strong>(Running)，CPU以外のリソースは全て獲得CPUリソースさえ獲得できれば<strong>実行可能状態</strong>(ready)，CPU以外のリソースの不足，もしくは他のプロセスからのデータ待ちの<strong>待ち状態</strong>(wait)，の３つの状態で存在する。</p>
<p>2.1<br>
　OS内におけるプロセスの状態は，（実行状態），（実行可能状態），（待ち状態）の３つの状態に分けることができる。（実行状態）から（実行可能状態）への状態遷移は優先度の高いプロセスの割込みや，CPUスケジューラにより割り当てられたCPU時間（クオンタム）を使った時に起こる。<br>
　プロセスの実行情報は，主にレジスタ情報が（PSW）に，それ以外の実行時間やプロセス名などの情報が（PCB）に格納されている。実行中のプロセスが中断された場合，これらの情報を保存しなければならない。この一連の操作を（コンテキスト）切り替えと呼び，最近のCPUには（PSW）を高速に保存する仕組みがある。</p>
<p>2.2 割込み時に，割込みの種類をベクタとして，割込み処理ルーチンに渡すのはなぜか，また，ベクタとして渡す以外の他の方法についても考査せよ。<br>
　割込みは，頻繁にかつ様々な原因で発生するため，その処理はできる限り高速に行わなければならない。割込みベクタを用いることで，OSは制御がどのアドレスに移されたかにより，割込みの原因を高速かつ容易に知ることができる。<br>
　また，割込みベクタを用いない方法として，状態（cause）レジスタを用いる方法がある。この場合，割り込みが発生した時点で，同一の割込み処理ルーチンに制御が移り，割込み処理ルーチン内で，状態レジスタを参照することにより，適切な割込み処理を行う。</p>
<p>2.3 OSを理解する上で，速度オーダーの理解は重要である。本書が想定する以下の速度を答えよ</p>
<ul>
<li>CPUの１命令実行   10^(-9)</li>
<li>主記憶からCPUに内容を伝送する速度 10^(-7)</li>
<li>2時記憶の読み出し（書き込み速度） 10^(-3)</li>
<li>人の反応速度  10^(-1)</li>
</ul>
<p>2.4 PCBの場合はA，PSWの場合はB，どちらにも含まれない場合はC<br>
プロセス識別子（A）  ユーザ名（A）    既実行時間（A）  実行優先度（A）  プログラムカウンタ（B）<br>
割込みマスク（B）    割込みベクタテーブル（C）    割込み処理ルーチン（C）</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[OS：OSとは]]></title>
        <id>https://zy080080.github.io/post/mq2xVP1Fs/</id>
        <link href="https://zy080080.github.io/post/mq2xVP1Fs/">
        </link>
        <updated>2021-01-11T11:25:54.000Z</updated>
        <summary type="html"><![CDATA[<p>教科書第1章　要点まとめ</p>
]]></summary>
        <content type="html"><![CDATA[<p>教科書第1章　要点まとめ</p>
<!-- more -->
<p>オペレーティングシステムは，ハードウェアの確保，ユーザインタフェース，入出力制御など，プログラム本体とは異なる制御を，プログラマが意識することなく，プログラムすることを可能とする一連の制御プログラムの集合体なのである。</p>
<p><strong>仮想化</strong>：オペレーティングシステムは『ハードウェアへのアクセスの容易性』，『ハードウェアリソースの確保の確認に対する容易性』を確保するために，有限個しかないハードウェアリソースを無限個，無限大のハードウェアリソースとしてプログラム側に提供すること。</p>
<p><strong>多重化</strong>：ハードウェアリソース数を，実際の数より多く見せる操作。</p>
<ul>
<li><strong>時分割多重化</strong>：時間軸上での多重化。時間を区切ることにより，ハードウェアリソースを複数のプログラムに交互に利用させる方式である。</li>
<li><strong>空間分割多重化</strong>：空間軸上での多重化。ハードウェアリソースを複数の領域に区切ることにより，複数のプログラムに別々の領域を利用させる方式である。</li>
</ul>
<p><strong>バッチ処理</strong>：ユーザがジョブをコンピュータに一括して依頼し，コンピュータはプログラムの実行前に一括に投入されたジョブに含まれる情報のみによって処理を行う方式。</p>
<ul>
<li>具体的には，実行時に必要とするリソース（CPU時間，メモリ量など），プログラム本体（ソースコード），データ（入力データ）が投入される。</li>
<li>特徴：実行上必要なリソースを全て実行前に宣言すること。</li>
<li>利点：
<ul>
<li>スケジューリングが単純。
<ul>
<li>前もってプログラムが必要とするリソースが分かる。</li>
<li>複数のジョブのスケジューリングが楽（必要リソースの少ないジョブを優先的に実行すると，全ジョブの平均待ち時間が短くなる）。</li>
<li>ジョブの切り替えも少なくてすむため，無駄が少ない。</li>
</ul>
</li>
</ul>
</li>
<li>欠点：
<ul>
<li>前もって全てを決めないとジョブが投入できない。Ï</li>
</ul>
</li>
</ul>
<p><strong>対話処理</strong>：プログラムの実行中に入力が必要となった場合に，ユーザがその時点で入力を行い，プログラムの実行を制御する処理形態。</p>
<ul>
<li>対話処理を採用する場合の代表的なプロセス実行形態として<strong>タイムシェアリングシステム（時分割処理方式　time sharing sysytem:TSS）</strong></li>
</ul>
<p><strong>クオンタム</strong>：一回に割当てられる時間。</p>
<p><strong>TSS（Time Sharing System 時分割処理方式）</strong>：複数のプロセスに非常に短い時間（10^(-3)秒程度）単位でCPUの実行権を与え，対話処理を実行中の各プロセスにあたかもCPUを占有しているかのように見せかけるCPUの時間軸方向の仮想化手法。(人的反应慢，反应不过来被分配给其他处理的时间，从人的视角来看好像只在处理一个process而已)</p>
<ul>
<li>使っていないCPU時間を他に割り当てる。割り当てられる単位時間（クオンタム）は数10ms。</li>
<li>利点：
<ul>
<li>自分の他に大きなプロセスがあっても，そのプロセスが終わるまで長い時間待たされたりしない。（バッチ処理ではありうる）。各プロセスの待ち時間は短い。</li>
<li>ユーザから見ても，対話的に入力してからその反応が返ってくるまでの時間（レスポンスタイム）が短くなる。</li>
</ul>
</li>
</ul>
<p><strong>リアルタイム処理</strong>：あるジョブやプロセスが発生した時点から決めた時間内に実行を保証する処理。</p>
<p><strong>分散処理</strong>：複数のコンピュータを同時に用いて一連の処理を行う方式。</p>
<hr>
<p>1.<strong>オペレーティングシステム</strong>の目的は，ハードウェアリソース，ソフトウェアリソースの利用時における容易性，効率性の向上である。<br>
2.リソースを配分される単位を<strong>プロセス</strong>と呼び，ユーザから見たコンピュータに依頼する仕事のまとまりを<strong>ジョブ</strong>と呼ぶ。<br>
3.オペレーティングシステムの基本的な枠組みは，リソースの<strong>仮想化</strong>と仮想化されたリソースの<strong>スケジューリング</strong>にある。<br>
4.プログラムの処理形態は，<strong>バッチ処理</strong>と<strong>対話処理</strong>の２つが基本である。他にも，リアルタイム処理や分散処理などオペレーティングシステムの処理形態は広がりつつある。<br>
5.効率化の指標は大きく分けて，プログラムの実行を依頼してから結果が帰ってくるまでの時間の尺度である<strong>レスポンズタイム</strong>（対話処理の場合），<strong>ターンアラウンドタイム</strong>(バッチ処理の場合)と，一定時間内にコンピュータシステムが行う仕事量の尺度である<strong>スループット</strong>がある。</p>
<p>1.1 プロセスとジョブの違いについて説明せよ。<br>
　プロセスは，オペレーティングシステム側から見たリソースの割り当て対象であり，ジョブとは，ユーザ側から見たオペレーティングシステムに対して処理を依頼する，ひとまとまりの仕事を表す。したがって，１つのジョブは通常１つ以上のプロセスから構成される。なお，ジョブという言葉は，バッチシステムでは一般的であり，TSSを基本とするオペレーティングシステムではあまり用いられない。</p>
<p>1.2 空間分割によるリソースの多重化時に考えられるオーバーヘッドについて説明せよ。<br>
　空間分割による多重化を行うためには，プロセスの必要とするリソースがどのような位置に配置されても，プロセス側からは同様のアドレスを指定することにより，アクセスの可能である設計が必要となる。したがって，オペレーティングシステムでは，プロセス側で指定するリソースの位置と実際の物理的なリソースの位置との間の変換を行う作業が必要となる。</p>
<p>1.3 個人が使用するオペレーティングシスレムにおいてもTSSが一般的に用いられている。この理由を，ユーザからみた利便性，システム資源の有効利用の面から考察せよ。<br>
　ユーザからみた利便性：個人が使用するオペレーティングシステムにおいても，複数の仕事を同時に実行することが必要である。ネットワーク入出力，華やかなグラフィカルユーザインターフェース，個人のスケジュール管理ソフトなどなど縁の下の力持ち的なソフトウェアの増加など，ユーザの利便性を追求することを目的とするプロセスは増大の一方である。したがって，複数のプロセスを同時に実行可能なTSS環境は必須である。<br>
　システム資源の有効利用：個人が使用するオペレーティングシステムで実行されているプロセスの大部分は，CPUリソースをほとんど消費しない待ちの状態が多い（ゲームなどCPUリソースを大量に使うアプリケーションの実行時は除く）。例えば，スケジュール管理ソフトは決められた時刻が来た時，もしくはユーザのスケジュール入力時のみ動作すれば良い。したがって，TSSによるCPUリソースの多重化を行っても見かけ上のプログラム実行速度の変化がないだけでなく，待ち時間の有効利用はシステム資源の有効利用となる。</p>
<p>1.4 時分割多重化の利点と欠点<br>
　時分割多重化の利点には，時間を区切ることにより，ハードウェアリソースを複数のプログラムに交互に利用させることができ，CPUなど空間分割が不可能な時に利用できることがある。ただし，欠点として，使用者が切り替わる時に無駄（オーバヘッド）が発生する。電子機械では，短い時間で切り替えるため，切り替え回数が増加すると，オーバヘッドも増加してしまう。</p>
<p>数値の重要性</p>
<ul>
<li>
<p>計算機の基本周期（クロック）は？</p>
<ul>
<li>１単位の処理時間10<sup>(-9)秒(1ns)，クロックだと10</sup>9回(1GHz)</li>
</ul>
</li>
<li>
<p>主記憶へのアクセス遅延は？</p>
<ul>
<li>10^(-7)秒(100ns)</li>
</ul>
</li>
<li>
<p>2次記憶へのアクセス遅延は？</p>
<ul>
<li>10^(-2)秒(5ms~10ms)</li>
</ul>
</li>
<li>
<p>人間のキーボード入力速度は？</p>
<ul>
<li>10^(-1)秒</li>
</ul>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[コンパイラ：字句解析]]></title>
        <id>https://zy080080.github.io/post/u0YDg1pii/</id>
        <link href="https://zy080080.github.io/post/u0YDg1pii/">
        </link>
        <updated>2020-10-10T05:35:39.000Z</updated>
        <summary type="html"><![CDATA[<p>コンパイラが行う最初の処理が字句解析である。字句解析では，文字の並びを解析し，トークンの並びへ変換する作業をする。</p>
]]></summary>
        <content type="html"><![CDATA[<p>コンパイラが行う最初の処理が字句解析である。字句解析では，文字の並びを解析し，トークンの並びへ変換する作業をする。</p>
<!-- more -->
<h2 id="トークン">トークン</h2>
<p>ソースプログラムを構成する単位は，文字である。この文字を一文字以上集めて，“単語”に相当する単位にしたものがトークンである。</p>
<p>コンパイラは構文解析を行う前に，文字の並びをトークンの並びに分解する。これは，構文解析をやりやすくするためや，処理方式に違いがあることなどから，一般的に行われるものである。</p>
<p>トークンの並びに変換する作業を，文字の列を句（トークン）の列に分解する作業であることから，**字句解析（Lexical Analasis）**と呼ぶ。</p>
<h2 id="トークンの種類">トークンの種類</h2>
<h3 id="識別子とキーワード">識別子とキーワード</h3>
<p>識別子は，通常の変数名や関数名のような名前を意味する。しかし，変数名か関数名かといった区別は，字句解析では判断できないため，予約語を除き，全て識別子という区分で扱うことになる。</p>
<p>通常のプログラミング言語では，‘if’や‘while’のような単語を，キーワードあるいは予約語（reserved word）として特別に扱っている。</p>
<p>このキーワードは，２つのグループに分けられる。<br>
１つは，ifやwhileのように，プログラムの構造を示すものであり，他のものに定義をされると解析が困難になるため，予約されている。<br>
もう１つは，intやfloatのように，特別なデータ型を表すもので，他のものに定義されても解析上は支障がないが，意味などで混乱を起こす可能性があるため，他の定義が禁止されている。</p>
<h3 id="定数">定数</h3>
<p>（1）整数<br>
コンパイラ内部で扱う時に，整数のオーバーフローが起きてはいけない。</p>
<p>（2）浮動小数点数<br>
3.2や0.25のほか，3.5e2や2e-4も浮動小数点数である。さらに，eの前後に空白を許すか許さないか，といった書き方の違いもあり，これらをか使うプログラミング言語に応じて正しく認識する必要がある。また，誤差の問題も注意が必要である。</p>
<p>（3）文字と文字列<br>
エスケープ文字（C言語の「\」）の扱いを必要とする。また，文字列と文字が異なるのかどうかの違いがある。<br>
C言語では，'a'は文字で，&quot;a&quot;は文字列となる。ところが，Pascalでは'a'は文字で，'ab'が文字列である。そして，文字として'を含める時にどのように記載するかは言語によって違っている。</p>
<h3 id="空白改行注釈">空白，改行，注釈</h3>
<p>空白や改行は，C言語では，トークンの区切りという意味だけを持っている。<br>
注釈は一般にプログラムを構成する要素ではない。<br>
通常のプログラミング言語では，１つのトークンの間に注釈や空白を入れることはできない。</p>
<h2 id="字句解析の手法">字句解析の手法</h2>
<p>字句解析の処理は，入力文字に対する遷移図（オートマトン）と考えると比較的わかりやすい。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[コンパイラ：プログラムが動作する仕組みと言語が動作する仕組み]]></title>
        <id>https://zy080080.github.io/post/a4vitZ301/</id>
        <link href="https://zy080080.github.io/post/a4vitZ301/">
        </link>
        <updated>2020-10-03T04:06:13.000Z</updated>
        <summary type="html"><![CDATA[<p>コンパイラの役割はプログラミング言語を用いて開発するソフトウェア，つまり人が記述したテキストをコンピュータが解釈，実行できる機械語に変換することである。<br>
ここでは，コンパイラの目的を理解するために，コンピュータ上でソフトウェアが動作する基本的な仕組みと，プログラミング言語として定義された文法，さらに，この文法にしたがって開発するソフトウェアの目的を説明する。</p>
]]></summary>
        <content type="html"><![CDATA[<p>コンパイラの役割はプログラミング言語を用いて開発するソフトウェア，つまり人が記述したテキストをコンピュータが解釈，実行できる機械語に変換することである。<br>
ここでは，コンパイラの目的を理解するために，コンピュータ上でソフトウェアが動作する基本的な仕組みと，プログラミング言語として定義された文法，さらに，この文法にしたがって開発するソフトウェアの目的を説明する。</p>
<!-- more -->
<h2 id="コンピュータの仕組み">コンピュータの仕組み</h2>
<p>基本的な構成要素は，頭脳となるCPUと情報を記憶するメモリである。<br>
CPUはメモリに記録されているプログラムを制御装置に読み出して分析，解釈し，演算装置が，その意味を理解しながら実行する。<br>
CPUは人が支持する人間の言葉を直接的に理解できないため，プログラムとして記述された指示書を読みながら実行することになる。この指示書を記述する文法がプログラミング言語である。コンピュータが理解できる言語は，CPUとメモリが連携して行う計算処理の手順を定義できなければならない。<br>
ここで注意すべき点は，<strong>現在のコンピュータは定義されていないことや矛盾する手順を人間のように自動的に発見して補正する能力も知識もない</strong>ことである。</p>
<p>CPU内部にも，計算に用いる数値を格納するレジスタと呼ばれる一種の記憶装置を保持している。計算を行う演算装置は，このレジスタに記録されている数値を読み取り，また一時的な計算結果を書き出しながら計算を実行していく。レジスタは演算装置とのやりとりを高速に行えるが，利用できる数は限定的である。<br>
この構成からCPUの計算速度が向上する，つまりコンピュータ性能が高くなるためには，まず演算装置が高速に計算できること，加えてレジスタへの読み込み，書き込みが高速にできること，さらに一度にレジスタに読み込める情報量を大きくすることが必要になる。</p>
<p>計算手順と計算に用いる情報を定義しているプログラムは，実行する前にはハードディスクなどに格納されている。利用者がプログラムの起動をコンピュータに指示すると，プログラムがメモリに記録（ロード）される。そして，CPUは記憶装置から，順次，計算単位を一時的に内部記憶装置に読み込みながら，このデータに対して計算を加えて，結果を記憶装置に登録する手順を繰り返す。以上の操作により，利用者は最終的に期待する計算結果を得ることができる。</p>
<h2 id="言語が動作する仕組み">言語が動作する仕組み</h2>
<ul>
<li>自然言語（Natural Language）
<ul>
<li>自然発生的にできた言語。日本語，英語が該当する。</li>
</ul>
</li>
<li>人工言語（Artificial Language）
<ul>
<li>ある情報を伝える目的のために人が作り出した言語。モールス信号やプログラミング言語が該当する。</li>
</ul>
</li>
</ul>
<p>人工言語であるプログラミング言語は自然言語と異なり，コンピュータが解釈して実行できるように人が設計した言語であるため，その解釈は厳密的に行われなければならず，曖昧な表現は許されない。</p>
<p>コンピュータには通常，あらかじめ定義されている一通りの意味でしか解釈できない。このように人工言語に属するプログラミング言語は，自然言語と比較して目的が限定的であり，かつ表現力に乏しい言語といえる。</p>
<h3 id="プログラミング言語と機械語">プログラミング言語と機械語</h3>
<figure data-type="image" tabindex="1"><img src="https://zy080080.github.io//post-images/1601697611773.png" alt="" loading="lazy"></figure>
<p>プログラミング言語は，人が目的に応じてアルゴリズムを記述しやすいように開発された人工言語であるため，プログラムをCPUが理解できる機械語で表現されるコードに置き換えて解釈する仕組みが必要となる。</p>
<p>この変換を行うツールとして，コンパイラー，インタプリタ，クロスコンパイラなどの処理形態がある。</p>
<p>機械語プログラムは起動するために必要な初期情報を格納したスタートアップルーチンと呼ばれる情報を持ち，<strong>コンピュータの仕組みに対応して</strong>命令群とデータ群を保持している。<br>
コンピュータに動作させたい手順は，スタートアップルーチンを呼び出したのち，命令群とデータ群による計算を繰り返すことにより実行される。<br>
このため，コンパイラがプログラムを機械語に変換してアルゴリズムを実行させるためには，コンピュータの仕組みを強く意識することが重要である。</p>
<figure data-type="image" tabindex="2"><img src="https://zy080080.github.io//post-images/1601698151224.png" alt="" loading="lazy"></figure>
<p>コンパイラを設計する際に行われる検討項目を以下に示す。これらの検討は，プログラムから機械語への変換を効率よく行うとともに，コンピュータ性能を十分に生かすことが可能な機械語コードを生成するために行う。</p>
<ul>
<li>木（解析木など）や中間言語（アセンブラ）など言語の構造の整理</li>
<li>生成する機械語の構造</li>
<li>プログラムの構造や意味に対応した字句，構文，意味解析</li>
<li>機械語コードの生成と最適化</li>
<li>コンパイラやインタプリタ，プリプロセッサ，マクロなど，言語処理の形態</li>
<li>プートストラップ，コンパイラの自動生成，コンパイラ作成などのツール利用</li>
</ul>
<h2 id="言語を動作させる工夫">言語を動作させる工夫</h2>
<p>コンピュータのCPuに依存する言語を，一般に低レベル言語と呼ぶ。これに対して手続き型言語，関数型言語，論理型言語，オブジェクト指向型言語など，プログラムとして表現したい意味に依存して設計された言語は，特定のCPU種別に依存することなく独立に開発されるため，高レベル言語と呼ばれる。</p>
<hr>
<h2 id="コンパイラ">コンパイラ</h2>
<p>コンパイラは高級言語で書かれたプログラムをそれと等価な機械語プログラム等に変換する言語処理系（Language Processing System）である。</p>
<h2 id="言語処理系">言語処理系</h2>
<p>あるプログラミング言語で書かれたプログラムを，同じ動作をする別のプログラミング言語のプログラムに変換するソフトウェアを言語処理系という。</p>
<p>変更前のプログラム＝ソース ，その言語＝ソース言語<br>
変更後のプログラム＝オブジェクト，その言語＝オブジェクト言語（目的言語）</p>
<p>Cコンパイラ（言語処理系）<br>
ソース言語＝C言語，目的言語＝アセンブリ言語</p>
<p>アセンブラ（言語処理系）<br>
ソース言語＝アセンブリ言語，目的言語＝機械語</p>
<h2 id="リンカ">リンカ</h2>
<p>オブジェクトファイルとライブラリを結合し，動作可能な実行形式プログラムを出力。</p>
<h2 id="プリプロセッサ">プリプロセッサ</h2>
<p>ソースプログラムをコンパイル可能な形に整える。ヘッダーファイルの取り込み，マクロ展開（#defineなど）</p>
<h2 id="分割コンパイル">分割コンパイル</h2>
<p>システム開発は，通常複数人のチームで行う。<br>
そのため，一般的ににプログラムは複数のソースプログラムによって構成される。</p>
<ul>
<li>各ソースプログラムを個別にコンパイルして結合することを<strong>分割コンパイル</strong>という。</li>
<li>個別にコンパイルしたオブジェクトファイルの結合は，リンカーが行う。</li>
<li>各ソースプログラムは完全ではないため，Cコードと呼ぶことがある。</li>
</ul>
<h2 id="コンパイラの構造">コンパイラの構造</h2>
<p>コンパイラの本体は，以下の４つの処理で構成される。</p>
<ol>
<li>字句解析（Lexical Analysis）ソースプログラムのテキストを，字句要素（lexeme）と呼ばれる文字列に分割する。</li>
<li>構文解析（Syntax Analysis）トークン列を解析して文法にしたがっているかを確認し，構文木を生成する。</li>
<li>意味解析（Semantic Analysis）意味の観点でプログラムの正しさを確認する。</li>
<li>コード生成（Code Generation）アセンブリ言語のコードを生成する。</li>
</ol>
]]></content>
    </entry>
</feed>